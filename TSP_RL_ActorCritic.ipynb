{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fbc009f-8ee7-41cb-8ded-08836b63bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2bffd7-28c0-434d-9c6e-791ff9811d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_data_txt = open('tsp_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3990d91-0bf8-4461-b4b5-f8a8cafe05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = tsp_data_txt.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10879ae-e336-4add-9642-e1698018bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_data_txt = open('tsp_dataset.txt')\n",
    "data = {}\n",
    "lines = tsp_data_txt.readlines()\n",
    "distance_matrix = np.zeros((len(lines),len(lines)))\n",
    "for i,line in enumerate(lines):\n",
    "    for j,element in enumerate((line.split('\\n')[0].split('       '))):\n",
    "        if(element == ''):\n",
    "            continue\n",
    "        \n",
    "        distance_matrix[i][j-1] = int(element.strip())\n",
    "data['distance_matrix']= distance_matrix\n",
    "data['reward_matrix'] = [1 for i  in range(0,len(distance_matrix))]\n",
    "data['depot'] = 0\n",
    "data['n_state'] = sum(list(range(1,len(distance_matrix))))\n",
    "data['n_action'] = len(distance_matrix)\n",
    "data['visited_nodes'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d88b8a95-46e6-4687-b320-f40ac09de9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(data['distance_matrix'])):\n",
    "    data['distance_matrix'][i][i] = 9999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a753ec-78af-4e46-b3bf-3f366159f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_reward(envp):\n",
    "    for i in range(0,envp['n_state']):\n",
    "        for j in range(0,envp['n_action']):\n",
    "            for k in range(0,envp['n_action']):\n",
    "                if k==0:\n",
    "                    env['P'][i][j][k][2]= 10\n",
    "                    env['P'][i][j][k][3]= True\n",
    "                    break\n",
    "    return envp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a11bf8-07f6-4eba-9bdf-1d64bf101fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialze_value(env):\n",
    "    initial_P = 1/(env['n_action']-1)\n",
    "    env['P'] = {}\n",
    "    \n",
    "    #P[state][action] = [(prob, next state, reward, done), ...]\n",
    "    \n",
    "    for i in range(0,env['n_state']):\n",
    "        env['P'][i] ={}\n",
    "        \n",
    "        if(i==104):\n",
    "            for j in range(0,env['n_action']):\n",
    "                env['P'][i][j] = []\n",
    "                initial_P = 1/(env['n_action']-1)\n",
    "                for k in range(0,env['n_action']):\n",
    "                    if (j == env['depot'] and k == env['depot']):\n",
    "                        ini_temp = [1,k,10,True]\n",
    "                        env['P'][i][j].append(ini_temp)\n",
    "                        initial_P = 0\n",
    "                        continue\n",
    "                    ini_temp = [initial_P,k,data['reward_matrix'][k],False]\n",
    "                    env['P'][i][j].append(ini_temp)\n",
    "        else:\n",
    "            for j in range(0,env['n_action']):\n",
    "                env['P'][i][j] = []\n",
    "                for k in range(0,env['n_action']):\n",
    "                    ini_temp = [initial_P,k,data['reward_matrix'][k],False]\n",
    "                    env['P'][i][j].append(ini_temp)\n",
    "    \n",
    "    env['state'] = []\n",
    "    for si in range(0,env['n_state']):\n",
    "        env['state'].append([])\n",
    "        for n in range(0,env['n_action']):\n",
    "            env['state'][si].append(initial_P)\n",
    "    \n",
    "    env['state'] = np.asarray(env['state']).reshape((env['n_action'],-1))\n",
    "            \n",
    "    return env\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a9f558-75c1-4fe6-99b5-3f9da9c29f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0002\n",
    "gamma         = 0.98\n",
    "\n",
    "# Run configurations\n",
    "print_every = 100\n",
    "num_episodes = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ce9e81-cd17-4b0d-900b-3b79ff0d9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, n_state, n_action):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.shared_layer = nn.Linear(n_state,256)\n",
    "        self.policy_layer = nn.Linear(256,n_action)\n",
    "        self.value_layer = nn.Linear(256,n_action)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        self.data = []\n",
    "        \n",
    "    def get_action_with_softmax(self,prob):\n",
    "        visited_index = []\n",
    "        prob[0][0] =  torch.tensor(float('-inf'))\n",
    "        first_index = Categorical(F.softmax(prob[0][:15])).sample()\n",
    "       \n",
    "        visited_index.append(first_index)\n",
    "        for pi,pb in enumerate(prob[1:]):    \n",
    "            if pi <13:\n",
    "                prob[pi+1][0] =  torch.tensor(float('-inf'))\n",
    "            for vi,viv in enumerate(visited_index):\n",
    "                prob[pi+1][viv] =  torch.tensor(float('-inf'))\n",
    "            temp_index = Categorical(F.softmax(prob[pi+1][:15])).sample()\n",
    "            visited_index.append(temp_index)\n",
    "        return visited_index,F.softmax(prob)\n",
    "    \n",
    "    def policy(self, state):\n",
    "        x = F.relu(self.shared_layer(state))\n",
    "        x = self.policy_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        prob = self.policy(torch.from_numpy(state).float())\n",
    "        return prob\n",
    "      \n",
    "    \n",
    "    def value(self, state):\n",
    "        x = F.relu(self.shared_layer(state.float()).float()).float()\n",
    "        value = self.value_layer(x).float()\n",
    "        return value\n",
    "    \n",
    "    def save(self, transition):\n",
    "        self.data.append(transition)\n",
    "        \n",
    "    \n",
    "    def get_policy_action(self,state):\n",
    "        prob = self.policy(torch.from_numpy(state).float())\n",
    "        action,sprob = self.get_action_with_softmax(prob)\n",
    "\n",
    "        return action,state,prob,self.get_reward(action)\n",
    "\n",
    "    def get_reward(self,visit_list):\n",
    "        depot =0\n",
    "        distance = torch.tensor(data['distance_matrix'])[0][visit_list[0]]\n",
    "        prev_cite = visit_list[0]\n",
    "        for i in range(1,14):\n",
    "            distance+= torch.tensor(data['distance_matrix'])[prev_cite][visit_list[i]]\n",
    "            prev_cite =visit_list[i]\n",
    "\n",
    "        distance+= torch.tensor(data['distance_matrix'])[prev_cite][visit_list[14]]\n",
    "        return distance\n",
    "    \n",
    "    def update(self):\n",
    "        action,state, prob,reward = self.data.pop()\n",
    "        self.value(torch.tensor(env['state']).float())\n",
    "        td_target = reward - self.value(torch.tensor(env['state']).float())\n",
    "        td_error = td_target - self.value(torch.tensor(env['state']).float())\n",
    "        \n",
    "        dist = self.policy(torch.tensor(env['state']).float())\n",
    "\n",
    "        action,sprob = self.get_action_with_softmax(dist)\n",
    "        loss_actor =  sprob * td_error.detach()\n",
    "\n",
    "        #loss_critic = F.smooth_l1_loss(self.value(torch.tensor(state)), td_target.detach()).float()\n",
    "        loss_critic = (self.value(torch.tensor(env['state']).float()).detach() + td_target.detach())\n",
    "        \n",
    "        loss = -1*(loss_actor + loss_critic)\n",
    "  \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.mean().backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def get_prob_for_update(self,ction,prob):\n",
    "        prob_list = torch.zeros((15,15))\n",
    "        for pi,pl in enumerate(prob_list):\n",
    "            prob_list[pi]+= prob[action[pi]]\n",
    "        return prob_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dfd4706-f278-454c-a770-e7e9b1c35d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = initialze_value(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbfb59f5-d6e2-4e94-a4d1-f1a7a2db77a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic = ActorCritic(n_state=105, n_action=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25edf26b-658e-4aad-b7f5-3fea708bb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, env, print_every=200, num_episodes=10000, learning_rate=0.00002):\n",
    "    episodic_reward = np.zeros([num_episodes])\n",
    "    for n_epi in range(num_episodes):\n",
    "        done = False\n",
    "        state = env['state']\n",
    "        action,state,sprob,reward = agent.get_policy_action(state)\n",
    "\n",
    "        agent.save((action,state,sprob,reward))\n",
    "        episodic_reward[n_epi] += reward                     \n",
    "        agent.update()\n",
    "        if (n_epi==0) or ((n_epi+1) % print_every == 0):\n",
    "            print(\"# of episode :{}, return : {:.1f}\".format(n_epi, episodic_reward[n_epi]))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be66bb69-2814-4923-b5e6-4f47fd4058b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_25616/34783881.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  first_index = Categorical(F.softmax(prob[0][:15])).sample()\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_25616/34783881.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  temp_index = Categorical(F.softmax(prob[pi+1][:15])).sample()\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_25616/34783881.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return visited_index,F.softmax(prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of episode :0, return : 687.0\n",
      "# of episode :199, return : 613.0\n",
      "# of episode :399, return : 674.0\n",
      "# of episode :599, return : 634.0\n",
      "# of episode :799, return : 721.0\n",
      "# of episode :999, return : 706.0\n",
      "# of episode :1199, return : 705.0\n",
      "# of episode :1399, return : 706.0\n",
      "# of episode :1599, return : 706.0\n",
      "# of episode :1799, return : 690.0\n",
      "# of episode :1999, return : 706.0\n",
      "# of episode :2199, return : 705.0\n",
      "# of episode :2399, return : 706.0\n",
      "# of episode :2599, return : 705.0\n",
      "# of episode :2799, return : 705.0\n",
      "# of episode :2999, return : 705.0\n",
      "# of episode :3199, return : 705.0\n",
      "# of episode :3399, return : 705.0\n",
      "# of episode :3599, return : 705.0\n",
      "# of episode :3799, return : 705.0\n",
      "# of episode :3999, return : 705.0\n",
      "# of episode :4199, return : 705.0\n",
      "# of episode :4399, return : 705.0\n",
      "# of episode :4599, return : 705.0\n",
      "# of episode :4799, return : 705.0\n",
      "# of episode :4999, return : 705.0\n",
      "# of episode :5199, return : 705.0\n",
      "# of episode :5399, return : 705.0\n",
      "# of episode :5599, return : 705.0\n",
      "# of episode :5799, return : 705.0\n",
      "# of episode :5999, return : 689.0\n",
      "# of episode :6199, return : 689.0\n",
      "# of episode :6399, return : 689.0\n",
      "# of episode :6599, return : 689.0\n",
      "# of episode :6799, return : 689.0\n",
      "# of episode :6999, return : 689.0\n",
      "# of episode :7199, return : 689.0\n",
      "# of episode :7399, return : 689.0\n",
      "# of episode :7599, return : 689.0\n",
      "# of episode :7799, return : 689.0\n",
      "# of episode :7999, return : 689.0\n",
      "# of episode :8199, return : 689.0\n",
      "# of episode :8399, return : 689.0\n",
      "# of episode :8599, return : 689.0\n",
      "# of episode :8799, return : 689.0\n",
      "# of episode :8999, return : 689.0\n",
      "# of episode :9199, return : 689.0\n",
      "# of episode :9399, return : 689.0\n",
      "# of episode :9599, return : 689.0\n",
      "# of episode :9799, return : 689.0\n",
      "# of episode :9999, return : 689.0\n"
     ]
    }
   ],
   "source": [
    "train(actor_critic, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ed07c-99a3-4bf1-9956-a8b2b3324f45",
   "metadata": {},
   "source": [
    "# actor_critic.get_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4256982a-0c6c-4c95-9d67-6bb220d1647d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_25616/34783881.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  first_index = Categorical(F.softmax(prob[0][:15])).sample()\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_25616/34783881.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  temp_index = Categorical(F.softmax(prob[pi+1][:15])).sample()\n",
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_25616/34783881.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return visited_index,F.softmax(prob)\n"
     ]
    }
   ],
   "source": [
    "a,b =actor_critic.get_action_with_softmax(torch.tensor(env['state']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a9a5fbf-d862-4e52-8573-450d1d00d14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 7, 11, 6, 10, 4, 5, 14, 8, 3, 9, 13, 12, 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(a_i) for a_i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fdb2650-84b2-40c4-b89b-40e2254b2520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_map_route(data,tour_list=None):\n",
    "    scaled_distance_matrix = data['distance_matrix']/100\n",
    "    x_point = []\n",
    "    y_point = []\n",
    "    for di,dis in enumerate(scaled_distance_matrix[0]):\n",
    "        if di%2 ==0 :\n",
    "            x_point.append(dis-di*0.05*dis)\n",
    "            y_point.append(di*0.01*dis)\n",
    "        elif di%3==0:\n",
    "            x_point.append(dis/2)\n",
    "            y_point.append(dis/2)\n",
    "        else:\n",
    "            x_point.append(di*0.05*dis)\n",
    "            y_point.append(dis-di*0.05*dis)\n",
    "            \n",
    "    plt.plot(x_point,y_point,'bo')\n",
    "    plt.plot(x_point[0],y_point[0],'bo',color='red')\n",
    "    line_x = []\n",
    "    line_y = []\n",
    "    if tour_list!=None:\n",
    "        for tl in tour_list:\n",
    "            line_x.append(x_point[tl])\n",
    "            line_y.append(y_point[tl])\n",
    "            \n",
    "        plt.plot(line_x,line_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "134939b2-57c5-4651-b2d3-29b3d99ff6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_25616/2649083656.py:17: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"bo\" (-> color='b'). The keyword argument will take precedence.\n",
      "  plt.plot(x_point[0],y_point[0],'bo',color='red')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_map_route(data,[2, 1, 7, 11, 6, 10, 4, 5, 14, 8, 3, 9, 13, 12, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11778c44-b10d-4242-8dba-03d3318a8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(visit_list):\n",
    "    depot =0\n",
    "    distance = (data['distance_matrix'])[0][visit_list[0]]\n",
    "    prev_cite = visit_list[0]\n",
    "    for i in range(1,14):\n",
    "        distance+= (data['distance_matrix'])[prev_cite][visit_list[i]]\n",
    "        prev_cite =visit_list[i]\n",
    "\n",
    "    distance+= (data['distance_matrix'])[prev_cite][visit_list[14]]\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "334ce6d0-ee1a-428f-87d8-2f40e46490b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reward([2, 1, 7, 11, 6, 10, 4, 5, 14, 8, 3, 9, 13, 12, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a5c3a-a235-4d89-a90f-683350cc19e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
