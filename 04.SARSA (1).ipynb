{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qFHj12lvVwd"
   },
   "source": [
    "# SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1634260338227,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "T3WuaKUKvFhb",
    "outputId": "14a40911-52bd-4566-f76f-f37265ba8867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plt version:[3.2.2]\n",
      "gym version:[0.17.3]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "print (\"plt version:[%s]\"%(matplotlib.__version__))\n",
    "print (\"gym version:[%s]\"%(gym.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hW6uoeLZvZIL"
   },
   "source": [
    "##### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "executionInfo": {
     "elapsed": 815,
     "status": "ok",
     "timestamp": 1634260339462,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "BMavIN9lvUle"
   },
   "outputs": [],
   "source": [
    "def display_q_value(Q, title=\"Q Function\",fig_size=8,text_fs=9,title_fs=15):\n",
    "    \"\"\"\n",
    "    Display Q value\n",
    "    \"\"\"\n",
    "    n_state, n_action = Q.shape\n",
    "    nRow = 4\n",
    "    # Triangle patches for each action\n",
    "    lft_tri = np.array([[0,0],[-0.5,-0.5],[-0.5,0.5]])\n",
    "    dw_tri = np.array([[0,0],[-0.5,0.5],[0.5,0.5]])\n",
    "    up_tri = np.array([[0,0],[0.5,-0.5],[-0.5,-0.5]])\n",
    "    rgh_tri = np.array([[0,0],[0.5,0.5],[0.5,-0.5]])\n",
    "    # Color\n",
    "    high_color = np.array([1.0, 0.0, 0.0, 0.8])\n",
    "    low_color  = np.array([1.0, 1.0, 1.0, 0.8])\n",
    "    fig = plt.figure(figsize=(fig_size,fig_size))\n",
    "    plt.title(title,fontsize=title_fs)  \n",
    "    for i in range(nRow):\n",
    "        for j in range(nRow):\n",
    "            s = i*nRow+j\n",
    "            min_q = np.min(Q[s])\n",
    "            max_q = np.max(Q[s])\n",
    "            for a in range(n_action):\n",
    "                q_value = Q[s,a]\n",
    "                ratio = (q_value - min_q)/(max_q - min_q + 1e-10) \n",
    "                if ratio > 1: clr = high_color\n",
    "                elif ratio < 0: clr = low_color\n",
    "                else: clr = high_color*ratio + low_color*(1-ratio)\n",
    "                if a == 0: # Left arrow\n",
    "                    plt.gca().add_patch(plt.Polygon([j,i]+lft_tri, color=clr, ec='k'))\n",
    "                    plt.text(j-0.25, i+0.0,\"%.2f\"%(q_value),fontsize=text_fs,va='center', ha='center')\n",
    "                if a == 1: # Down arrow\n",
    "                    plt.gca().add_patch(plt.Polygon([j,i]+dw_tri, color=clr, ec='k'))\n",
    "                    plt.text(j-0.0, i+0.25,\"%.2f\"%(q_value),fontsize=text_fs,va='center', ha='center')\n",
    "                if a == 2: # Right arrow\n",
    "                    plt.gca().add_patch(plt.Polygon([j,i]+rgh_tri, color=clr, ec='k'))\n",
    "                    plt.text(j+0.25, i+0.0,\"%.2f\"%(q_value),fontsize=text_fs,va='center', ha='center')\n",
    "                if a == 3: # Up arrow\n",
    "                    plt.gca().add_patch(plt.Polygon([j,i]+up_tri, color=clr, ec='k'))\n",
    "                    plt.text(j-0.0, i-0.25,\"%.2f\"%(q_value),fontsize=text_fs,va='center', ha='center')\n",
    "    plt.xlim([-0.5,nRow-0.5])\n",
    "    plt.xticks(range(nRow))\n",
    "    plt.ylim([-0.5,nRow-0.5])\n",
    "    plt.yticks(range(nRow))\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_matrix(M,strs='',fontsize=15,cmap='turbo',title='Title',title_fs=15,\n",
    "                     fig_size=8,REMOVE_TICK_LABELS=True):\n",
    "    \"\"\"\n",
    "    Visualize a matrix colors and strings \n",
    "    \"\"\"\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    n_row,n_col = M.shape[0],M.shape[1]\n",
    "    fig,ax = plt.subplots(figsize=(fig_size,fig_size))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    im = ax.imshow(M,cmap=plt.get_cmap(cmap),extent=(0,n_col,n_row,0),\n",
    "              interpolation='nearest',aspect='equal')\n",
    "    ax.set_xticks(np.arange(0,n_col,1))\n",
    "    ax.set_yticks(np.arange(0,n_row,1))\n",
    "    ax.grid(color='w', linewidth=2)\n",
    "    ax.set_frame_on(False)\n",
    "    x,y = np.meshgrid(np.arange(0,n_col,1.0),np.arange(0,n_row,1.0))\n",
    "    if len(strs) == n_row*n_col:\n",
    "        idx = 0\n",
    "        for x_val,y_val in zip(x.flatten(), y.flatten()):\n",
    "            c = strs[idx]\n",
    "            idx = idx + 1\n",
    "            ax.text(x_val+0.5,y_val+0.5,c,va='center', ha='center',size=fontsize)\n",
    "    cax = divider.append_axes('right', size='5%', pad=0.05)            \n",
    "    fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "    fig.suptitle(title,size=title_fs) \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    if REMOVE_TICK_LABELS:\n",
    "        plt.setp(ax.get_xticklabels(),visible=False)\n",
    "        plt.setp(ax.get_yticklabels(),visible=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fO0JnmIvcxs"
   },
   "source": [
    "### SARSA\n",
    "\n",
    "'SARSA' is a model-free algorithm which does not require $P(s'|s,a)$ where the Q value function should be estimated by samples. The policy evaluation step for Q value function is:\n",
    "\n",
    " $Q_{k+1}(s,a) = \\sum_{s'} \\left[r(s,a,s') + \\gamma \\sum_{a'} Q_{k}(s',a') \\pi(a'|s') \\right] P(s'|s,a)$\n",
    "\n",
    "Here, we update the Q value function using `temporal difference (TD) learning`:\n",
    "\n",
    "$Q_{new}(S_{t}, A_{t}) \\leftarrow Q_{old}(S_{t}, A_{t}) + \\alpha (\n",
    " R_{t+1} + \\gamma Q_{old}(S_{t+1},A_{t+1}) \n",
    "- Q_{old}(S_{t}, A_{t}))$\n",
    "\n",
    "where $ R_{t+1} + \\gamma Q_{old}(S_{t+1},A_{t+1}) $ is the TD target. \n",
    "\n",
    "We can update the estimator for the Q value function in an online fashion where $(S_{t},A_{t},R_{t+1},S_{t+1},A_{t+1})$ is needed.\n",
    "\n",
    "> TD target is $R_{t+1} + \\gamma Q(S_{t+1},A_{t+1})$\n",
    "\n",
    "> TD error is $R_{t+1} + \\gamma Q(S_{t+1},A_{t+1}) - Q(S_{t},A_{t})$\n",
    "\n",
    "Algorithm\n",
    "--\n",
    "---\n",
    "For every time step\n",
    "\n",
    "Policy Evaluation\n",
    "\n",
    "- Given $(S_{t},A_{t},R_{t+1},S_{t+1},A_{t+1})$\n",
    "\n",
    "- TD target is $R_{t+1} + \\gamma Q(S_{t+1},A_{t+1})$\n",
    "\n",
    "- TD error is $R_{t+1} + \\gamma Q(S_{t+1},A_{t+1}) - Q(S_{t},A_{t})$\n",
    "\n",
    "- $Q[S_{t}, A_{t}] = Q[S_{t}, A_{t}] + \\alpha \\text{TD error}$\n",
    "\n",
    "Policy Improvement\n",
    "\n",
    "- $\\pi(a|s) = \\frac{\\epsilon}{m} + (1-\\epsilon) \\mathbf{1}\\left(a = \\max_{a'} Q(s,a')\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1634260339894,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "F-nJJjpCvaoI"
   },
   "outputs": [],
   "source": [
    "class SARSAAgent():\n",
    "    def __init__(self, n_state, n_action, epsilon=1.0, alpha=0.1, gamma=0.99):\n",
    "        \"\"\"\n",
    "        Initialize a SARSA agent\n",
    "        \"\"\"\n",
    "        self.n_state = n_state\n",
    "        self.n_action = n_action\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        # Q value\n",
    "        self.Q = np.zeros([n_state,n_action])\n",
    "        \n",
    "    def update_Q(self,state,action,reward,state_prime,action_prime,done):\n",
    "        \"\"\"\n",
    "        Update Q value using TD learning\n",
    "        \"\"\"\n",
    "        Q_old = self.Q[state][action]\n",
    "        if done:\n",
    "            td_target = reward # for the last step, Q = reward\n",
    "        else:\n",
    "            td_target = reward + self.gamma*self.Q[state_prime][action_prime]\n",
    "        td_error = td_target - Q_old\n",
    "        # Update Q value\n",
    "        self.Q[state,action] = Q_old + self.alpha*td_error \n",
    "        \n",
    "    def update_epsilon(self,epsilon):\n",
    "        self.epsilon = np.min([epsilon,1.0]) # decay\n",
    "        \n",
    "    def get_action(self,state):\n",
    "        \"\"\"\n",
    "        Get action\n",
    "        \"\"\"\n",
    "        if np.random.uniform() < self.epsilon: # random with epsilon probability \n",
    "            action = np.random.randint(0, high=self.n_action)\n",
    "        else: # greedy action\n",
    "            action = np.argmax(self.Q[state])\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E63J7TwtwrT4"
   },
   "source": [
    "### Run SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10442,
     "status": "ok",
     "timestamp": 1634260351594,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "rEm-0H1uvflg",
    "outputId": "b5825fa7-e61c-4efe-a519-bd94d2efdb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARSA done.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v0')\n",
    "n_state = env.observation_space.n\n",
    "n_action = env.action_space.n\n",
    "agent = SARSAAgent(n_state,n_action,epsilon=1.0,alpha=0.1,gamma=0.999)\n",
    "\n",
    "# Loop\n",
    "n_episode = 10000\n",
    "for e_idx in range(n_episode):\n",
    "    state = env.reset() # reset environment, select initial \n",
    "    action = agent.get_action(state)\n",
    "    done = False\n",
    "    while not done:\n",
    "        state_prime,reward,done,info = env.step(action) # step \n",
    "        if done:\n",
    "            # Reward modification to handle sparse reward\n",
    "            if reward == 0:  reward = -5 # let hole to have -1 reward\n",
    "            else: reward = +10 # let goal to have +10 reward\n",
    "        else:\n",
    "            reward = -0.01\n",
    "        action_prime = agent.get_action(state_prime) # Get next action\n",
    "        agent.update_Q(state,action,reward,state_prime,action_prime,done) # online learning\n",
    "        state = state_prime\n",
    "        action = action_prime\n",
    "    agent.update_epsilon(100/(e_idx+1)) # Decaying epsilon\n",
    "print (\"SARSA done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnP9TE2VwsjE"
   },
   "outputs": [],
   "source": [
    "# Plot env\n",
    "E = np.zeros(shape=(4,4))\n",
    "strs = ['S','F','F','F',\n",
    "        'F','H','F','H',\n",
    "        'F','F','F','H',\n",
    "        'H','F','F','G',]\n",
    "E[0,0] = 1 # Start\n",
    "E[1,1]=E[1,3]=E[2,3]=E[3,0]=2 # Hole\n",
    "E[3,3] = 3 # Goal\n",
    "visualize_matrix(E,strs=strs,cmap='Pastel1',title='FrozenLake',fig_size=7)\n",
    "\n",
    "# Plot Q\n",
    "display_q_value(agent.Q,title=\"SARSA\",\n",
    "                fig_size=8,text_fs=8,title_fs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWKB14wlwuj8"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "gamma = 0.99\n",
    "env = gym.make('FrozenLake-v0')\n",
    "obs = env.reset() # reset\n",
    "ret = 0\n",
    "state = 0\n",
    "for tick in range(1000):\n",
    "    print(\"\\n tick:[{}]\".format(tick))\n",
    "    env.render(mode='human')\n",
    "    action = agent.get_action(state) # select action\n",
    "    next_obs,reward,done,info = env.step(action)\n",
    "    obs = next_obs\n",
    "    ret = reward + gamma*ret \n",
    "    state = next_obs\n",
    "    if done: break\n",
    "env.render(mode='human')\n",
    "env.close()\n",
    "print (\"Return is [{:.3f}]\".format(ret))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zNwY7Y8Wm38"
   },
   "source": [
    "### Cliff Walking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1634260353164,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "s8EOljQKlJs0"
   },
   "outputs": [],
   "source": [
    "from gym.envs.toy_text.cliffwalking import CliffWalkingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1634260353165,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "ymG_ZcxcSQwG"
   },
   "outputs": [],
   "source": [
    "env = CliffWalkingEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1634260353165,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "pima-an5SSdq",
    "outputId": "df4e5e4e-4811-4352-b36a-03c117b238c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1634260353166,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "15T6P-qUSUcN",
    "outputId": "ccb42f96-398a-44c0-f5a7-b868db568cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states: 48\n",
      "Number of actions that an agent can take: 4\n"
     ]
    }
   ],
   "source": [
    "# 4x12 grid = 48 states\n",
    "print (\"Number of states:\", env.nS)\n",
    "print (\"Number of actions that an agent can take:\", env.nA)\n",
    "action_space = [\"up\", \"right\", \"down\", \"left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1634260353166,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "CzzQKf2iSWw7",
    "outputId": "c6362793-8b84-4aeb-ad31-db7fa7bbf6c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state 36\n",
      "Transitions from current state: {0: [(1.0, 24, -1, False)], 1: [(1.0, 36, -100, False)], 2: [(1.0, 36, -1, False)], 3: [(1.0, 36, -1, False)]}\n"
     ]
    }
   ],
   "source": [
    "print (\"Current state\", env.s)\n",
    "print (\"Transitions from current state:\", env.P[env.s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1634260353167,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "V_vJ9gu_Ylik"
   },
   "outputs": [],
   "source": [
    "for s in range(48):\n",
    "    for a in range(4):\n",
    "        if env.P[s][a][0][2] == -100:\n",
    "            env.P[s][a][0] = (env.P[s][a][0][0], env.P[s][a][0][1], env.P[s][a][0][2], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1634260353167,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "YlEH2UVsZK34",
    "outputId": "083b59c1-cfdf-41b1-f29d-2cab8107de5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: [(1.0, 0, -1, False)],\n",
       "  1: [(1.0, 1, -1, False)],\n",
       "  2: [(1.0, 12, -1, False)],\n",
       "  3: [(1.0, 0, -1, False)]},\n",
       " 1: {0: [(1.0, 1, -1, False)],\n",
       "  1: [(1.0, 2, -1, False)],\n",
       "  2: [(1.0, 13, -1, False)],\n",
       "  3: [(1.0, 0, -1, False)]},\n",
       " 2: {0: [(1.0, 2, -1, False)],\n",
       "  1: [(1.0, 3, -1, False)],\n",
       "  2: [(1.0, 14, -1, False)],\n",
       "  3: [(1.0, 1, -1, False)]},\n",
       " 3: {0: [(1.0, 3, -1, False)],\n",
       "  1: [(1.0, 4, -1, False)],\n",
       "  2: [(1.0, 15, -1, False)],\n",
       "  3: [(1.0, 2, -1, False)]},\n",
       " 4: {0: [(1.0, 4, -1, False)],\n",
       "  1: [(1.0, 5, -1, False)],\n",
       "  2: [(1.0, 16, -1, False)],\n",
       "  3: [(1.0, 3, -1, False)]},\n",
       " 5: {0: [(1.0, 5, -1, False)],\n",
       "  1: [(1.0, 6, -1, False)],\n",
       "  2: [(1.0, 17, -1, False)],\n",
       "  3: [(1.0, 4, -1, False)]},\n",
       " 6: {0: [(1.0, 6, -1, False)],\n",
       "  1: [(1.0, 7, -1, False)],\n",
       "  2: [(1.0, 18, -1, False)],\n",
       "  3: [(1.0, 5, -1, False)]},\n",
       " 7: {0: [(1.0, 7, -1, False)],\n",
       "  1: [(1.0, 8, -1, False)],\n",
       "  2: [(1.0, 19, -1, False)],\n",
       "  3: [(1.0, 6, -1, False)]},\n",
       " 8: {0: [(1.0, 8, -1, False)],\n",
       "  1: [(1.0, 9, -1, False)],\n",
       "  2: [(1.0, 20, -1, False)],\n",
       "  3: [(1.0, 7, -1, False)]},\n",
       " 9: {0: [(1.0, 9, -1, False)],\n",
       "  1: [(1.0, 10, -1, False)],\n",
       "  2: [(1.0, 21, -1, False)],\n",
       "  3: [(1.0, 8, -1, False)]},\n",
       " 10: {0: [(1.0, 10, -1, False)],\n",
       "  1: [(1.0, 11, -1, False)],\n",
       "  2: [(1.0, 22, -1, False)],\n",
       "  3: [(1.0, 9, -1, False)]},\n",
       " 11: {0: [(1.0, 11, -1, False)],\n",
       "  1: [(1.0, 11, -1, False)],\n",
       "  2: [(1.0, 23, -1, False)],\n",
       "  3: [(1.0, 10, -1, False)]},\n",
       " 12: {0: [(1.0, 0, -1, False)],\n",
       "  1: [(1.0, 13, -1, False)],\n",
       "  2: [(1.0, 24, -1, False)],\n",
       "  3: [(1.0, 12, -1, False)]},\n",
       " 13: {0: [(1.0, 1, -1, False)],\n",
       "  1: [(1.0, 14, -1, False)],\n",
       "  2: [(1.0, 25, -1, False)],\n",
       "  3: [(1.0, 12, -1, False)]},\n",
       " 14: {0: [(1.0, 2, -1, False)],\n",
       "  1: [(1.0, 15, -1, False)],\n",
       "  2: [(1.0, 26, -1, False)],\n",
       "  3: [(1.0, 13, -1, False)]},\n",
       " 15: {0: [(1.0, 3, -1, False)],\n",
       "  1: [(1.0, 16, -1, False)],\n",
       "  2: [(1.0, 27, -1, False)],\n",
       "  3: [(1.0, 14, -1, False)]},\n",
       " 16: {0: [(1.0, 4, -1, False)],\n",
       "  1: [(1.0, 17, -1, False)],\n",
       "  2: [(1.0, 28, -1, False)],\n",
       "  3: [(1.0, 15, -1, False)]},\n",
       " 17: {0: [(1.0, 5, -1, False)],\n",
       "  1: [(1.0, 18, -1, False)],\n",
       "  2: [(1.0, 29, -1, False)],\n",
       "  3: [(1.0, 16, -1, False)]},\n",
       " 18: {0: [(1.0, 6, -1, False)],\n",
       "  1: [(1.0, 19, -1, False)],\n",
       "  2: [(1.0, 30, -1, False)],\n",
       "  3: [(1.0, 17, -1, False)]},\n",
       " 19: {0: [(1.0, 7, -1, False)],\n",
       "  1: [(1.0, 20, -1, False)],\n",
       "  2: [(1.0, 31, -1, False)],\n",
       "  3: [(1.0, 18, -1, False)]},\n",
       " 20: {0: [(1.0, 8, -1, False)],\n",
       "  1: [(1.0, 21, -1, False)],\n",
       "  2: [(1.0, 32, -1, False)],\n",
       "  3: [(1.0, 19, -1, False)]},\n",
       " 21: {0: [(1.0, 9, -1, False)],\n",
       "  1: [(1.0, 22, -1, False)],\n",
       "  2: [(1.0, 33, -1, False)],\n",
       "  3: [(1.0, 20, -1, False)]},\n",
       " 22: {0: [(1.0, 10, -1, False)],\n",
       "  1: [(1.0, 23, -1, False)],\n",
       "  2: [(1.0, 34, -1, False)],\n",
       "  3: [(1.0, 21, -1, False)]},\n",
       " 23: {0: [(1.0, 11, -1, False)],\n",
       "  1: [(1.0, 23, -1, False)],\n",
       "  2: [(1.0, 35, -1, False)],\n",
       "  3: [(1.0, 22, -1, False)]},\n",
       " 24: {0: [(1.0, 12, -1, False)],\n",
       "  1: [(1.0, 25, -1, False)],\n",
       "  2: [(1.0, 36, -1, False)],\n",
       "  3: [(1.0, 24, -1, False)]},\n",
       " 25: {0: [(1.0, 13, -1, False)],\n",
       "  1: [(1.0, 26, -1, False)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 24, -1, False)]},\n",
       " 26: {0: [(1.0, 14, -1, False)],\n",
       "  1: [(1.0, 27, -1, False)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 25, -1, False)]},\n",
       " 27: {0: [(1.0, 15, -1, False)],\n",
       "  1: [(1.0, 28, -1, False)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 26, -1, False)]},\n",
       " 28: {0: [(1.0, 16, -1, False)],\n",
       "  1: [(1.0, 29, -1, False)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 27, -1, False)]},\n",
       " 29: {0: [(1.0, 17, -1, False)],\n",
       "  1: [(1.0, 30, -1, False)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 28, -1, False)]},\n",
       " 30: {0: [(1.0, 18, -1, False)],\n",
       "  1: [(1.0, 31, -1, False)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 29, -1, False)]},\n",
       " 31: {0: [(1.0, 19, -1, False)],\n",
       "  1: [(1.0, 32, -1, False)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 30, -1, False)]},\n",
       " 32: {0: [(1.0, 20, -1, False)],\n",
       "  1: [(1.0, 33, -1, False)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 31, -1, False)]},\n",
       " 33: {0: [(1.0, 21, -1, False)],\n",
       "  1: [(1.0, 34, -1, False)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 32, -1, False)]},\n",
       " 34: {0: [(1.0, 22, -1, False)],\n",
       "  1: [(1.0, 35, -1, False)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 33, -1, False)]},\n",
       " 35: {0: [(1.0, 23, -1, False)],\n",
       "  1: [(1.0, 35, -1, False)],\n",
       "  2: [(1.0, 47, -1, True)],\n",
       "  3: [(1.0, 34, -1, False)]},\n",
       " 36: {0: [(1.0, 24, -1, False)],\n",
       "  1: [(1.0, 36, -100, True)],\n",
       "  2: [(1.0, 36, -1, False)],\n",
       "  3: [(1.0, 36, -1, False)]},\n",
       " 37: {0: [(1.0, 25, -1, False)],\n",
       "  1: [(1.0, 36, -100, True)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 36, -1, False)]},\n",
       " 38: {0: [(1.0, 26, -1, False)],\n",
       "  1: [(1.0, 36, -100, True)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 36, -100, True)]},\n",
       " 39: {0: [(1.0, 27, -1, False)],\n",
       "  1: [(1.0, 36, -100, True)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 36, -100, True)]},\n",
       " 40: {0: [(1.0, 28, -1, False)],\n",
       "  1: [(1.0, 36, -100, True)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 36, -100, True)]},\n",
       " 41: {0: [(1.0, 29, -1, False)],\n",
       "  1: [(1.0, 36, -100, True)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 36, -100, True)]},\n",
       " 42: {0: [(1.0, 30, -1, False)],\n",
       "  1: [(1.0, 36, -100, True)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 36, -100, True)]},\n",
       " 43: {0: [(1.0, 31, -1, False)],\n",
       "  1: [(1.0, 36, -100, True)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 36, -100, True)]},\n",
       " 44: {0: [(1.0, 32, -1, False)],\n",
       "  1: [(1.0, 36, -100, True)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 36, -100, True)]},\n",
       " 45: {0: [(1.0, 33, -1, False)],\n",
       "  1: [(1.0, 36, -100, True)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 36, -100, True)]},\n",
       " 46: {0: [(1.0, 34, -1, False)],\n",
       "  1: [(1.0, 47, -1, True)],\n",
       "  2: [(1.0, 36, -100, True)],\n",
       "  3: [(1.0, 36, -100, True)]},\n",
       " 47: {0: [(1.0, 35, -1, False)],\n",
       "  1: [(1.0, 47, -1, True)],\n",
       "  2: [(1.0, 47, -1, True)],\n",
       "  3: [(1.0, 36, -100, True)]}}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1634260353429,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "_n5saYr6SZdi",
    "outputId": "444da700-831e-4197-fe9c-c180515df9da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 36\n",
      "Reward recieved: -100\n",
      "Terminal state: True\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from time import sleep\n",
    "\n",
    "is_terminal = False\n",
    "env.render()\n",
    "while not is_terminal:\n",
    "    rnd_action = random.randint(0, 3)\n",
    "    print(\"Action taken:\", action_space[rnd_action])\n",
    "    next_state, reward, is_terminal, t_prob = env.step(rnd_action)\n",
    "    print(\"Transition probability:\", t_prob)\n",
    "    print(\"Next state:\", next_state)\n",
    "    print(\"Reward recieved:\", reward)\n",
    "    print(\"Terminal state:\", is_terminal)\n",
    "    env.render()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4916,
     "status": "ok",
     "timestamp": 1634260358339,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "uShpMB0KTlJg",
    "outputId": "fb57e4ab-380b-4900-ce7d-dc92dd657af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARSA done.\n"
     ]
    }
   ],
   "source": [
    "n_state = env.observation_space.n\n",
    "n_action = env.action_space.n\n",
    "agent = SARSAAgent(n_state,n_action,epsilon=1.0,alpha=0.1,gamma=0.999)\n",
    "\n",
    "# Loop\n",
    "n_episode = 10000\n",
    "for e_idx in range(n_episode):\n",
    "    state = env.reset() # reset environment, select initial \n",
    "    action = agent.get_action(state)\n",
    "    done = False\n",
    "    while not done:\n",
    "        state_prime, reward, done, info = env.step(action) # step \n",
    "        action_prime = agent.get_action(state_prime) # Get next action\n",
    "        agent.update_Q(state, action, reward, state_prime, action_prime ,done) # learns Q\n",
    "        state = state_prime\n",
    "        action = action_prime\n",
    "    agent.update_epsilon(100/(e_idx+1)) # Decaying epsilon\n",
    "print (\"SARSA done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15168,
     "status": "ok",
     "timestamp": 1634260373493,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "WtVAatJqSvKj",
    "outputId": "4792dfdd-2f15-4bd8-a4c1-4cc423436532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: up\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 24\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: up\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 12\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 13\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  x  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 14\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  x  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 15\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  x  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 16\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  x  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 17\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  x  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 18\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  x  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 19\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  x  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 20\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  x  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 21\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  x  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 22\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  x  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 23\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: down\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 35\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: down\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 47\n",
      "Reward recieved: -1\n",
      "Terminal state: True\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_terminal = False\n",
    "state = env.reset()\n",
    "env.render()\n",
    "while not is_terminal:\n",
    "    action = agent.get_action(state)\n",
    "    print(\"Action taken:\", action_space[action])\n",
    "    next_state, reward, is_terminal, t_prob = env.step(action)\n",
    "    print(\"Transition probability:\", t_prob)\n",
    "    print(\"Next state:\", next_state)\n",
    "    print(\"Reward recieved:\", reward)\n",
    "    print(\"Terminal state:\", is_terminal)\n",
    "    state = next_state\n",
    "    env.render()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygC57cjwgSaA"
   },
   "source": [
    "When penalty is much larger (-100 -> -1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1634260474042,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "85VqIyHhgQ0p"
   },
   "outputs": [],
   "source": [
    "for s in range(48):\n",
    "    for a in range(4):\n",
    "        if env.P[s][a][0][2] == -100:\n",
    "            env.P[s][a][0] = (env.P[s][a][0][0], env.P[s][a][0][1], -1000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1634260474044,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "RZa_p1bGgQ0w",
    "outputId": "13d7f6b4-d131-4fcb-d0f8-deda6ef0b502"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: [(1.0, 0, -1, False)],\n",
       "  1: [(1.0, 1, -1, False)],\n",
       "  2: [(1.0, 12, -1, False)],\n",
       "  3: [(1.0, 0, -1, False)]},\n",
       " 1: {0: [(1.0, 1, -1, False)],\n",
       "  1: [(1.0, 2, -1, False)],\n",
       "  2: [(1.0, 13, -1, False)],\n",
       "  3: [(1.0, 0, -1, False)]},\n",
       " 2: {0: [(1.0, 2, -1, False)],\n",
       "  1: [(1.0, 3, -1, False)],\n",
       "  2: [(1.0, 14, -1, False)],\n",
       "  3: [(1.0, 1, -1, False)]},\n",
       " 3: {0: [(1.0, 3, -1, False)],\n",
       "  1: [(1.0, 4, -1, False)],\n",
       "  2: [(1.0, 15, -1, False)],\n",
       "  3: [(1.0, 2, -1, False)]},\n",
       " 4: {0: [(1.0, 4, -1, False)],\n",
       "  1: [(1.0, 5, -1, False)],\n",
       "  2: [(1.0, 16, -1, False)],\n",
       "  3: [(1.0, 3, -1, False)]},\n",
       " 5: {0: [(1.0, 5, -1, False)],\n",
       "  1: [(1.0, 6, -1, False)],\n",
       "  2: [(1.0, 17, -1, False)],\n",
       "  3: [(1.0, 4, -1, False)]},\n",
       " 6: {0: [(1.0, 6, -1, False)],\n",
       "  1: [(1.0, 7, -1, False)],\n",
       "  2: [(1.0, 18, -1, False)],\n",
       "  3: [(1.0, 5, -1, False)]},\n",
       " 7: {0: [(1.0, 7, -1, False)],\n",
       "  1: [(1.0, 8, -1, False)],\n",
       "  2: [(1.0, 19, -1, False)],\n",
       "  3: [(1.0, 6, -1, False)]},\n",
       " 8: {0: [(1.0, 8, -1, False)],\n",
       "  1: [(1.0, 9, -1, False)],\n",
       "  2: [(1.0, 20, -1, False)],\n",
       "  3: [(1.0, 7, -1, False)]},\n",
       " 9: {0: [(1.0, 9, -1, False)],\n",
       "  1: [(1.0, 10, -1, False)],\n",
       "  2: [(1.0, 21, -1, False)],\n",
       "  3: [(1.0, 8, -1, False)]},\n",
       " 10: {0: [(1.0, 10, -1, False)],\n",
       "  1: [(1.0, 11, -1, False)],\n",
       "  2: [(1.0, 22, -1, False)],\n",
       "  3: [(1.0, 9, -1, False)]},\n",
       " 11: {0: [(1.0, 11, -1, False)],\n",
       "  1: [(1.0, 11, -1, False)],\n",
       "  2: [(1.0, 23, -1, False)],\n",
       "  3: [(1.0, 10, -1, False)]},\n",
       " 12: {0: [(1.0, 0, -1, False)],\n",
       "  1: [(1.0, 13, -1, False)],\n",
       "  2: [(1.0, 24, -1, False)],\n",
       "  3: [(1.0, 12, -1, False)]},\n",
       " 13: {0: [(1.0, 1, -1, False)],\n",
       "  1: [(1.0, 14, -1, False)],\n",
       "  2: [(1.0, 25, -1, False)],\n",
       "  3: [(1.0, 12, -1, False)]},\n",
       " 14: {0: [(1.0, 2, -1, False)],\n",
       "  1: [(1.0, 15, -1, False)],\n",
       "  2: [(1.0, 26, -1, False)],\n",
       "  3: [(1.0, 13, -1, False)]},\n",
       " 15: {0: [(1.0, 3, -1, False)],\n",
       "  1: [(1.0, 16, -1, False)],\n",
       "  2: [(1.0, 27, -1, False)],\n",
       "  3: [(1.0, 14, -1, False)]},\n",
       " 16: {0: [(1.0, 4, -1, False)],\n",
       "  1: [(1.0, 17, -1, False)],\n",
       "  2: [(1.0, 28, -1, False)],\n",
       "  3: [(1.0, 15, -1, False)]},\n",
       " 17: {0: [(1.0, 5, -1, False)],\n",
       "  1: [(1.0, 18, -1, False)],\n",
       "  2: [(1.0, 29, -1, False)],\n",
       "  3: [(1.0, 16, -1, False)]},\n",
       " 18: {0: [(1.0, 6, -1, False)],\n",
       "  1: [(1.0, 19, -1, False)],\n",
       "  2: [(1.0, 30, -1, False)],\n",
       "  3: [(1.0, 17, -1, False)]},\n",
       " 19: {0: [(1.0, 7, -1, False)],\n",
       "  1: [(1.0, 20, -1, False)],\n",
       "  2: [(1.0, 31, -1, False)],\n",
       "  3: [(1.0, 18, -1, False)]},\n",
       " 20: {0: [(1.0, 8, -1, False)],\n",
       "  1: [(1.0, 21, -1, False)],\n",
       "  2: [(1.0, 32, -1, False)],\n",
       "  3: [(1.0, 19, -1, False)]},\n",
       " 21: {0: [(1.0, 9, -1, False)],\n",
       "  1: [(1.0, 22, -1, False)],\n",
       "  2: [(1.0, 33, -1, False)],\n",
       "  3: [(1.0, 20, -1, False)]},\n",
       " 22: {0: [(1.0, 10, -1, False)],\n",
       "  1: [(1.0, 23, -1, False)],\n",
       "  2: [(1.0, 34, -1, False)],\n",
       "  3: [(1.0, 21, -1, False)]},\n",
       " 23: {0: [(1.0, 11, -1, False)],\n",
       "  1: [(1.0, 23, -1, False)],\n",
       "  2: [(1.0, 35, -1, False)],\n",
       "  3: [(1.0, 22, -1, False)]},\n",
       " 24: {0: [(1.0, 12, -1, False)],\n",
       "  1: [(1.0, 25, -1, False)],\n",
       "  2: [(1.0, 36, -1, False)],\n",
       "  3: [(1.0, 24, -1, False)]},\n",
       " 25: {0: [(1.0, 13, -1, False)],\n",
       "  1: [(1.0, 26, -1, False)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 24, -1, False)]},\n",
       " 26: {0: [(1.0, 14, -1, False)],\n",
       "  1: [(1.0, 27, -1, False)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 25, -1, False)]},\n",
       " 27: {0: [(1.0, 15, -1, False)],\n",
       "  1: [(1.0, 28, -1, False)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 26, -1, False)]},\n",
       " 28: {0: [(1.0, 16, -1, False)],\n",
       "  1: [(1.0, 29, -1, False)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 27, -1, False)]},\n",
       " 29: {0: [(1.0, 17, -1, False)],\n",
       "  1: [(1.0, 30, -1, False)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 28, -1, False)]},\n",
       " 30: {0: [(1.0, 18, -1, False)],\n",
       "  1: [(1.0, 31, -1, False)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 29, -1, False)]},\n",
       " 31: {0: [(1.0, 19, -1, False)],\n",
       "  1: [(1.0, 32, -1, False)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 30, -1, False)]},\n",
       " 32: {0: [(1.0, 20, -1, False)],\n",
       "  1: [(1.0, 33, -1, False)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 31, -1, False)]},\n",
       " 33: {0: [(1.0, 21, -1, False)],\n",
       "  1: [(1.0, 34, -1, False)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 32, -1, False)]},\n",
       " 34: {0: [(1.0, 22, -1, False)],\n",
       "  1: [(1.0, 35, -1, False)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 33, -1, False)]},\n",
       " 35: {0: [(1.0, 23, -1, False)],\n",
       "  1: [(1.0, 35, -1, False)],\n",
       "  2: [(1.0, 47, -1, True)],\n",
       "  3: [(1.0, 34, -1, False)]},\n",
       " 36: {0: [(1.0, 24, -1, False)],\n",
       "  1: [(1.0, 36, -1000, True)],\n",
       "  2: [(1.0, 36, -1, False)],\n",
       "  3: [(1.0, 36, -1, False)]},\n",
       " 37: {0: [(1.0, 25, -1, False)],\n",
       "  1: [(1.0, 36, -1000, True)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 36, -1, False)]},\n",
       " 38: {0: [(1.0, 26, -1, False)],\n",
       "  1: [(1.0, 36, -1000, True)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 36, -1000, True)]},\n",
       " 39: {0: [(1.0, 27, -1, False)],\n",
       "  1: [(1.0, 36, -1000, True)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 36, -1000, True)]},\n",
       " 40: {0: [(1.0, 28, -1, False)],\n",
       "  1: [(1.0, 36, -1000, True)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 36, -1000, True)]},\n",
       " 41: {0: [(1.0, 29, -1, False)],\n",
       "  1: [(1.0, 36, -1000, True)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 36, -1000, True)]},\n",
       " 42: {0: [(1.0, 30, -1, False)],\n",
       "  1: [(1.0, 36, -1000, True)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 36, -1000, True)]},\n",
       " 43: {0: [(1.0, 31, -1, False)],\n",
       "  1: [(1.0, 36, -1000, True)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 36, -1000, True)]},\n",
       " 44: {0: [(1.0, 32, -1, False)],\n",
       "  1: [(1.0, 36, -1000, True)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 36, -1000, True)]},\n",
       " 45: {0: [(1.0, 33, -1, False)],\n",
       "  1: [(1.0, 36, -1000, True)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 36, -1000, True)]},\n",
       " 46: {0: [(1.0, 34, -1, False)],\n",
       "  1: [(1.0, 47, -1, True)],\n",
       "  2: [(1.0, 36, -1000, True)],\n",
       "  3: [(1.0, 36, -1000, True)]},\n",
       " 47: {0: [(1.0, 35, -1, False)],\n",
       "  1: [(1.0, 47, -1, True)],\n",
       "  2: [(1.0, 47, -1, True)],\n",
       "  3: [(1.0, 36, -1000, True)]}}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5433,
     "status": "ok",
     "timestamp": 1634260479788,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "Tz0PVUfbgZMF",
    "outputId": "11b14904-7e16-4fbf-ccac-9ff3a9b289c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARSA done.\n"
     ]
    }
   ],
   "source": [
    "n_state = env.observation_space.n\n",
    "n_action = env.action_space.n\n",
    "agent = SARSAAgent(n_state,n_action,epsilon=1.0,alpha=0.1,gamma=0.999)\n",
    "\n",
    "# Loop\n",
    "n_episode = 10000\n",
    "for e_idx in range(n_episode):\n",
    "    state = env.reset() # reset environment, select initial \n",
    "    action = agent.get_action(state)\n",
    "    done = False\n",
    "    while not done:\n",
    "        state_prime, reward, done, info = env.step(action) # step \n",
    "        action_prime = agent.get_action(state_prime) # Get next action\n",
    "        agent.update_Q(state, action, reward, state_prime, action_prime ,done) # learns Q\n",
    "        state = state_prime\n",
    "        action = action_prime\n",
    "    agent.update_epsilon(100/(e_idx+1)) # Decaying epsilon\n",
    "print (\"SARSA done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17187,
     "status": "ok",
     "timestamp": 1634260496953,
     "user": {
      "displayName": "Park Junhyun",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03476600599135589595"
     },
     "user_tz": -540
    },
    "id": "1vTrknhdgZMO",
    "outputId": "31c9e6c7-d947-41c9-8f41-a11add005e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: up\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 24\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: up\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 12\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: up\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 0\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 1\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  x  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 2\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  x  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 3\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  x  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 4\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  x  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 5\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  x  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 6\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  x  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 7\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  x  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 8\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  x  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 9\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  x  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 10\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  x  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: right\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 11\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: down\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 23\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: down\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 35\n",
      "Reward recieved: -1\n",
      "Terminal state: False\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  x\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Action taken: down\n",
      "Transition probability: {'prob': 1.0}\n",
      "Next state: 47\n",
      "Reward recieved: -1\n",
      "Terminal state: True\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_terminal = False\n",
    "state = env.reset()\n",
    "env.render()\n",
    "while not is_terminal:\n",
    "    action = agent.get_action(state)\n",
    "    print(\"Action taken:\", action_space[action])\n",
    "    next_state, reward, is_terminal, t_prob = env.step(action)\n",
    "    print(\"Transition probability:\", t_prob)\n",
    "    print(\"Next state:\", next_state)\n",
    "    print(\"Reward recieved:\", reward)\n",
    "    print(\"Terminal state:\", is_terminal)\n",
    "    state = next_state\n",
    "    env.render()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqReYBGggemE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hW6uoeLZvZIL",
    "6zNwY7Y8Wm38"
   ],
   "name": "04.SARSA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
