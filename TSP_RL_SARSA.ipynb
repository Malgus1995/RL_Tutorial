{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcd9cab-4082-4229-b0f0-22589d197382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc2af41-db3c-4bb5-84f9-8db53613b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_data_txt = open('tsp_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a872b996-dcf9-42ff-91ff-bbaeba48507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = tsp_data_txt.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ad38c2-7553-49d0-9697-9f8369eccf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_data_txt = open('tsp_dataset.txt')\n",
    "data = {}\n",
    "lines = tsp_data_txt.readlines()\n",
    "distance_matrix = np.zeros((len(lines),len(lines)))\n",
    "for i,line in enumerate(lines):\n",
    "    for j,element in enumerate((line.split('\\n')[0].split('       '))):\n",
    "        if(element == ''):\n",
    "            continue\n",
    "        \n",
    "        distance_matrix[i][j-1] = int(element.strip())\n",
    "data['distance_matrix']= distance_matrix\n",
    "data['reward_matrix'] = [1 for i  in range(0,len(distance_matrix))]\n",
    "data['depot'] = 0\n",
    "data['n_state'] = sum(list(range(1,len(distance_matrix))))\n",
    "data['n_action'] = len(distance_matrix)\n",
    "data['visited_nodes'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79eb7b73-ac1f-40d8-b3da-df3a9c75d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(data['distance_matrix'])):\n",
    "    data['distance_matrix'][i][i] = 9999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1967f48-e1b5-41b6-8a0d-2d954cb3a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_reward(envp):\n",
    "    for i in range(0,envp['n_state']):\n",
    "        for j in range(0,envp['n_action']):\n",
    "            for k in range(0,envp['n_action']):\n",
    "                if k==0:\n",
    "                    env['P'][i][j][k][2]= 10\n",
    "                    env['P'][i][j][k][3]= True\n",
    "                    break\n",
    "    return envp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace6d8d4-1c96-4d82-89f9-23d108e38e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialze_value(env):\n",
    "    initial_P = 1/(env['n_action']-1)\n",
    "    env['P'] = {}\n",
    "    \n",
    "    #P[state][action] = [(prob, next state, reward, done), ...]\n",
    "    \n",
    "    for i in range(0,env['n_state']):\n",
    "        env['P'][i] ={}\n",
    "        \n",
    "        if(i==104):\n",
    "            for j in range(0,env['n_action']):\n",
    "                env['P'][i][j] = []\n",
    "                initial_P = 1/(env['n_action']-1)\n",
    "                for k in range(0,env['n_action']):\n",
    "                    if (j == env['depot'] and k == env['depot']):\n",
    "                        ini_temp = [1,k,10,True]\n",
    "                        env['P'][i][j].append(ini_temp)\n",
    "                        initial_P = 0\n",
    "                        continue\n",
    "                    ini_temp = [initial_P,k,data['reward_matrix'][k],False]\n",
    "                    env['P'][i][j].append(ini_temp)\n",
    "        else:\n",
    "            for j in range(0,env['n_action']):\n",
    "                env['P'][i][j] = []\n",
    "                for k in range(0,env['n_action']):\n",
    "                    ini_temp = [initial_P,k,data['reward_matrix'][k],False]\n",
    "                    env['P'][i][j].append(ini_temp)\n",
    "            \n",
    "            \n",
    "    return env\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80dd078-395d-43ba-97f9-06ead966cdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543b5f42-3d7c-4582-a700-aa188d963a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = initialze_value(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8323c942-7477-45b6-bb0e-79a2c03f4b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARSAAgent():\n",
    "    def __init__(self,n_state,n_action,epsilon=1,alpha=0.1,gamma=0.99):\n",
    "        self.n_state = n_state\n",
    "        self.n_action= n_action\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma =gamma\n",
    "        self.Q = np.zeros([n_state,n_action])\n",
    "        \n",
    "    def update_Q(self, state,action,reward,state_prime, action_prime,done):\n",
    "        Q_old = self.Q[state,action]\n",
    "        if done :\n",
    "            td_target = reward\n",
    "        else :\n",
    "            td_target = self.gamma*self.Q[state_prime,action_prime]\n",
    "        td_error = td_target - Q_old\n",
    "        self.Q[state,action] = Q_old+self.alpha*td_error\n",
    "        \n",
    "        #choose E- greedy policy\n",
    "    def update_epsilon(self, epsilon):\n",
    "        self.epsilon = np.min([epsilon,1])\n",
    "\n",
    "    def get_action(self,state):\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            action = np.random.randint(0,high=self.n_action)\n",
    "        else:\n",
    "            action = np.argmax(self.Q[state])\n",
    "        return action\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7947931f-b9a8-46fc-a4ce-4f189b93ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_state = env['n_state']\n",
    "n_action = env['n_action']\n",
    "agent = SARSAAgent(n_state,n_action,epsilon=1.0,alpha=0.1,gamma=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97aed952-5a9f-42e3-bf94-00eedf82e6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sarsa done.\n"
     ]
    }
   ],
   "source": [
    "n_episiode = 100\n",
    "ini_env = env\n",
    "for e_idx in range(n_episiode):\n",
    "    env['visited_nodes'] = []\n",
    "    env = ini_env\n",
    "    state = env['depot']\n",
    "    env['visited_nodes'].append(state)\n",
    "    for s in range(0,env['n_state']-1):\n",
    "        for vn in env['visited_nodes']:\n",
    "            env['P'][s][vn][vn] = [0,vn,-1,False]\n",
    "    action = agent.get_action(state)\n",
    "    done = False\n",
    "    while not done:\n",
    "        if len(env['visited_nodes'])==15:\n",
    "            env['visited_nodes'] = []\n",
    "            break\n",
    "        prob,state_prime, reward,done  = env['P'][state][action][action]\n",
    "        action_prime = agent.get_action(state_prime)\n",
    "        agent.update_Q(state, action, reward, state_prime,action_prime, done)\n",
    "        state = state_prime\n",
    "        action = action_prime\n",
    "        \n",
    "        if action  not in env['visited_nodes']:\n",
    "            env['visited_nodes'].append(action)\n",
    "        \n",
    "    # agent.update_epsilon(1000/(e_idx+1)) # reduce randomness\n",
    "    agent.update_epsilon(1000/(e_idx+1)) # reduce update rate\n",
    "print(\"sarsa done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b772604-f4e5-45f0-9ddb-9a5fe4af76cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tick:[0]\n",
      "[]\n",
      "\n",
      " tick:[1]\n",
      "[1]\n",
      "\n",
      " tick:[2]\n",
      "[1, 11]\n",
      "\n",
      " tick:[3]\n",
      "[1, 11, 7]\n",
      "\n",
      " tick:[4]\n",
      "[1, 11, 7, 4]\n",
      "\n",
      " tick:[5]\n",
      "[1, 11, 7, 4, 10]\n",
      "\n",
      " tick:[6]\n",
      "[1, 11, 7, 4, 10, 8]\n",
      "\n",
      " tick:[7]\n",
      "[1, 11, 7, 4, 10, 8]\n",
      "\n",
      " tick:[8]\n",
      "[1, 11, 7, 4, 10, 8, 14]\n",
      "\n",
      " tick:[9]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6]\n",
      "\n",
      " tick:[10]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0]\n",
      "\n",
      " tick:[11]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5]\n",
      "\n",
      " tick:[12]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9]\n",
      "\n",
      " tick:[13]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9]\n",
      "\n",
      " tick:[14]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9]\n",
      "\n",
      " tick:[15]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9]\n",
      "\n",
      " tick:[16]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9]\n",
      "\n",
      " tick:[17]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9]\n",
      "\n",
      " tick:[18]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9]\n",
      "\n",
      " tick:[19]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9]\n",
      "\n",
      " tick:[20]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13]\n",
      "\n",
      " tick:[21]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13]\n",
      "\n",
      " tick:[22]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13]\n",
      "\n",
      " tick:[23]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13]\n",
      "\n",
      " tick:[24]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13]\n",
      "\n",
      " tick:[25]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13]\n",
      "\n",
      " tick:[26]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12]\n",
      "\n",
      " tick:[27]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12]\n",
      "\n",
      " tick:[28]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12]\n",
      "\n",
      " tick:[29]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12]\n",
      "\n",
      " tick:[30]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12]\n",
      "\n",
      " tick:[31]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12]\n",
      "\n",
      " tick:[32]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12]\n",
      "\n",
      " tick:[33]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12]\n",
      "\n",
      " tick:[34]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12, 3]\n",
      "\n",
      " tick:[35]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12, 3]\n",
      "\n",
      " tick:[36]\n",
      "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12, 3]\n",
      "Return is [24.472]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "gamma = 0.99\n",
    "env = ini_env\n",
    "ret = 0\n",
    "state = env['depot']\n",
    "visited_list = []\n",
    "for tick in range(1000):\n",
    "    print(\"\\n tick:[{}]\".format(tick))\n",
    "    print(visited_list)\n",
    "    action = agent.get_action(state) # select action\n",
    "    if action not in  visited_list:\n",
    "        visited_list.append(action)\n",
    "    _,next_obs,reward,done = env['P'][state][action][action]\n",
    "    obs = next_obs+state\n",
    "    ret = reward + gamma*ret \n",
    "    state = next_obs\n",
    "    \n",
    "    if len(visited_list)== 15: break\n",
    "print (\"Return is [{:.3f}]\".format(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10de2bfd-6d37-41be-8b5c-b2802bb80c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12, 3, 2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ba97909-b6a7-48ff-bb48-4f6627a0555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(visit_list):\n",
    "    depot =0\n",
    "    distance = (data['distance_matrix'])[0][visit_list[0]]\n",
    "    prev_cite = visit_list[0]\n",
    "    for i in range(1,14):\n",
    "        distance+= (data['distance_matrix'])[prev_cite][visit_list[i]]\n",
    "        prev_cite =visit_list[i]\n",
    "\n",
    "    distance+= (data['distance_matrix'])[prev_cite][visit_list[14]]\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a3a9d26-bc68-40d1-8580-15abf09b3817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reward([1, 11, 7, 4, 10, 8, 14, 6, 0, 5, 9, 13, 12, 3, 2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752e5ec-3aaf-4c30-92d1-b2a6a3c57b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KAMP",
   "language": "python",
   "name": "kamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
