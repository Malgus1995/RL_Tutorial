{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f807c159-be19-4207-aed0-dc2dff9efe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad18434-3ee3-4451-937c-fd356856b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_data_txt = open('tsp_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d37d8e-c9f1-49c1-b990-cc70775f14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = tsp_data_txt.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96e514d1-68a5-4b75-9ce0-d2579dae1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsp_data_txt = open('tsp_dataset.txt')\n",
    "data = {}\n",
    "lines = tsp_data_txt.readlines()\n",
    "distance_matrix = np.zeros((len(lines),len(lines)))\n",
    "for i,line in enumerate(lines):\n",
    "    for j,element in enumerate((line.split('\\n')[0].split('       '))):\n",
    "        if(element == ''):\n",
    "            continue\n",
    "        \n",
    "        distance_matrix[i][j-1] = int(element.strip())\n",
    "data['distance_matrix']= distance_matrix\n",
    "data['reward_matrix'] = [1 for i  in range(0,len(distance_matrix))]\n",
    "data['depot'] = 0\n",
    "data['n_state'] = len(distance_matrix)*len(distance_matrix)\n",
    "data['n_action'] = len(distance_matrix)\n",
    "data['visited_nodes'] = [0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ce23eea-4a2c-4d89-8b5d-02733a787b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(data['distance_matrix'])):\n",
    "    data['distance_matrix'][i][i] = 9999\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9a5b33-950f-4ada-ad42-e4bf87fefc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialze_value(env):\n",
    "    initial_P = 1/(env['n_action']-1)\n",
    "    env['P'] = {}\n",
    "    \n",
    "    #P[state][action] = [(prob, next state, reward, done), ...]\n",
    "    \n",
    "    for i in range(0,env['n_state']):\n",
    "        env['P'][i] ={}\n",
    "        for j in range(0,env['n_action']):\n",
    "            env['P'][i][j] = []\n",
    "            for k in range(0,env['n_action']):\n",
    "                ini_temp = [initial_P,k,data['reward_matrix'][k],False]\n",
    "                env['P'][i][j].append(ini_temp)\n",
    "            \n",
    "    return env\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "124744e8-c67b-44f6-bd53-9936c4d4a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_reward(envp):\n",
    "    for i in range(0,envp['n_action']):\n",
    "        for j in range(0,envp['n_action']):\n",
    "            for k in range(0,envp['n_action']):\n",
    "                if k==0:\n",
    "                    env['P'][i][j][k][2]= -9999\n",
    "                    env['P'][i][j][k][3]= True\n",
    "                    break\n",
    "    return envp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0e26274-70be-4c6c-9bc1-5f949d42f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = initialze_value(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64001f4a-67cc-4dbe-b124-d070eb09f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi = np.random.uniform(size=(env['n_state'],env['n_action']))\n",
    "Pi = Pi/np.sum(Pi,axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "63ed362c-aa0e-4138-bc4c-d942454bf5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(env,Pi,gamma=0.99,epsilon=1e-6):\n",
    "    \n",
    "    \n",
    "    # Extract environment information\n",
    "    n_state = env['n_state']\n",
    "    P = env['P']\n",
    "    # Random initial value function \n",
    "    V = np.random.uniform(size=(n_state,1))\n",
    "    # Loop\n",
    "    tick,V_dists,V_list = 0,[],[]\n",
    "    while True:\n",
    "        tick = tick + 1\n",
    "        V_prime = np.zeros((n_state,))\n",
    "        \n",
    "        rm_s_lst = []\n",
    "        for s in env['P'].keys(): # for all state\n",
    "            rm_a_lst = []\n",
    "            for a in env['P'][s].keys(): # for all actions\n",
    "                for prob,s_prime,reward,done in env['P'][s][a]: \n",
    "                    if(s in rm_s_lst and a in rm_a_list):\n",
    "                        prob*=0.00001\n",
    "                        reward*=-100\n",
    "                    else:\n",
    "                        prob*=10\n",
    "                        reward*=10\n",
    "                    \n",
    "                    V_prime[s] += (reward*(1/env['distance_matrix'][s//15][a])+gamma*V[s_prime]*(1/env['distance_matrix'][s//15][a]))*prob*Pi[s][a]\n",
    "                if a not in rm_a_lst:\n",
    "                    rm_a_lst.append(a)\n",
    "        if s not in rm_s_lst:\n",
    "            rm_s_lst.append(s)\n",
    "            \n",
    "        \n",
    "        V_dist = np.max(np.abs(V-V_prime))\n",
    "        V_dists.append(V_dist)\n",
    "        V = V_prime\n",
    "        V_list.append(V)\n",
    "        if V_dist < epsilon:\n",
    "            break\n",
    "        if(tick==100):\n",
    "            break\n",
    "    return V,V_dists,V_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "87e4f294-1c16-495b-8a3e-1dd51475ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "V,V_dists,V_list = policy_evaluation(env,Pi,gamma=0.99,epsilon=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0fdb4-18d1-4f55-851a-88648fac9adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "628be309-fb4f-4b6b-b459-86f300fca1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24be1b3a6d0>]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(V_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "34e48784-0665-4d3e-8b3e-c8e7df13d14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200//15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "344bf9c8-1d7e-47e4-a51b-a08136580c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement(env,\n",
    "                       V,\n",
    "                       gamma=0.99):\n",
    "    \"\"\"\n",
    "    Policy Improvement\n",
    "    \"\"\"\n",
    "    n_state = env['n_state']\n",
    "    act_space = env['n_action']\n",
    "    n_action =  env['n_action']\n",
    "    P = env['P']\n",
    "    Q = np.zeros((n_state,n_action))\n",
    "    # Loop\n",
    "    for s in P.keys(): # for all states\n",
    "        visited_lst = []\n",
    "        for a in P[s].keys(): # for all actions\n",
    "            for prob,s_prime,reward,done in P[s][a]:\n",
    "                if a in visited_lst:\n",
    "                    prob*=0.0001\n",
    "                    reward*=0.0001\n",
    "                Q[s,a] += (reward*(1/env['distance_matrix'][s//15][a]) + gamma*V[s_prime]*(1/env['distance_matrix'][s//15][a]))*prob\n",
    "                \n",
    "                tmp_Pi=np.zeros((n_state,n_action))\n",
    "                tmp_Pi[np.arange(env['n_state']),np.argmax(Q,axis=1)] = 1\n",
    "                for p in tmp_Pi:\n",
    "                    a =np.where(p==1)[0][0]\n",
    "                    if a not in visited_lst:\n",
    "                        visited_lst.append(a)\n",
    "            if(len(visited_lst)==15):\n",
    "                visited_lst=[]\n",
    "                \n",
    "    Pi = np.zeros((n_state,n_action))\n",
    "    Pi[np.arange(n_state),np.argmax(Q,axis=1)] = 1\n",
    "    return Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "62a5e8a5-74da-4cc4-8419-6f249968fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(env,gamma=0.99,epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Policy Iteration\n",
    "    \"\"\"\n",
    "    n_state = env['n_state']\n",
    "    act_space = env['n_action']\n",
    "    n_action =  env['n_action']\n",
    "    \n",
    "    Pi = np.random.uniform(size=(n_state,n_action))\n",
    "    Pi = Pi/np.sum(Pi,axis=1,keepdims=True)\n",
    "    \n",
    "    while True:\n",
    "        V,V_dists,V_list = policy_evaluation(env,Pi,gamma=gamma,epsilon=epsilon)\n",
    "        Pi_prime = policy_improvement(env,V,gamma=gamma) \n",
    "        \n",
    "                                \n",
    "        if (Pi == Pi_prime).all(): # if the policy does not change\n",
    "            break\n",
    "        Pi = Pi_prime\n",
    "    return Pi,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "9c0e5f41-9632-4dfc-8027-bee8ba9bd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pi,V = policy_iteration(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd2d63-c3a2-4f0f-b797-543ed9ea1153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "27a1c539-797e-4d07-bbd3-119d5de50bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tick:[0]\n",
      "[0]\n",
      "\n",
      " tick:[1]\n",
      "[0, 9]\n",
      "\n",
      " tick:[2]\n",
      "[0, 9, 14]\n",
      "\n",
      " tick:[3]\n",
      "[0, 9, 14, 3]\n",
      "\n",
      " tick:[4]\n",
      "[0, 9, 14, 3, 11]\n",
      "\n",
      " tick:[5]\n",
      "[0, 9, 14, 3, 11, 8]\n",
      "\n",
      " tick:[6]\n",
      "[0, 9, 14, 3, 11, 8, 1]\n",
      "\n",
      " tick:[7]\n",
      "[0, 9, 14, 3, 11, 8, 1, 6]\n",
      "\n",
      " tick:[8]\n",
      "[0, 9, 14, 3, 11, 8, 1, 6, 7]\n",
      "\n",
      " tick:[9]\n",
      "[0, 9, 14, 3, 11, 8, 1, 6, 7, 2]\n",
      "\n",
      " tick:[10]\n",
      "[0, 9, 14, 3, 11, 8, 1, 6, 7, 2, 5]\n",
      "\n",
      " tick:[11]\n",
      "[0, 9, 14, 3, 11, 8, 1, 6, 7, 2, 5, 13]\n",
      "\n",
      " tick:[12]\n",
      "[0, 9, 14, 3, 11, 8, 1, 6, 7, 2, 5, 13, 10]\n",
      "\n",
      " tick:[13]\n",
      "[0, 9, 14, 3, 11, 8, 1, 6, 7, 2, 5, 13, 10, 12]\n"
     ]
    }
   ],
   "source": [
    "# Initialize environment\n",
    "ret = 0\n",
    "env['visited_nodes'] =[0]\n",
    "for tick in range(100):\n",
    "    obs = np.random.choice(env['n_state'],1)[0]\n",
    "    action =np.where(Pi[obs][:]==1)[0][0]\n",
    "    while action in env['visited_nodes']:\n",
    "        obs = np.random.choice(env['n_state'],1)[0] # select action\n",
    "        action =np.where(Pi[obs][:]==1)[0][0]\n",
    "        if action not in env['visited_nodes']:\n",
    "            break\n",
    "        \n",
    "    print(\"\\n tick:[{}]\".format(tick))\n",
    "    print(env['visited_nodes'])\n",
    "    env['visited_nodes'].append(action)\n",
    "    #if(len(env['visited_nodes'])==14):\n",
    "    #    env =change_reward(env)\n",
    "    #next_obs,reward,done,info = env.step(action)\n",
    "    #obs = next_obs\n",
    "    #ret = reward + gamma*ret \n",
    "    if len(env['visited_nodes']) >14:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283734f8-6e9f-423e-852d-9688abca7c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
